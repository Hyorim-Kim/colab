{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPcdvJb/Lc16zk9UG/XUQwq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hyorim-Kim/numpi/blob/main/tfc24count.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Ba2uib9TRcJo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3e45de8-ba48-41bd-8f62-72d20bf8e609"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['고프다' '공부' '내일' '먹고' '먹지' '배가' '아니' '점심' '해야겠다' '해야지']\n",
            "{'고프다': 0, '아니': 6, '배가': 5, '내일': 2, '점심': 7, '먹지': 4, '공부': 1, '해야겠다': 8, '먹고': 3, '해야지': 9}\n",
            "['나는 배 고프다 아니 배가 고프다.']\n",
            "  (0, 0)\t2\n",
            "  (0, 5)\t1\n",
            "  (0, 6)\t1\n",
            "[[2 0 0 0 0 1 1 0 0 0]]\n"
          ]
        }
      ],
      "source": [
        "# 자연어 처리에서 특징추출이란 단어나 문장들을 어떤 특징 값으로 변환하는 것을 의미~\n",
        "# 문자로 구성된 데이터를 모델에 적용할 수 있도록 특징을 추출해 수치화한다.\n",
        "# 단어의 수를 파악해 문장을 분석하는 방법\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "textData = ['나는 배 고프다 아니 배가 고프다.', '내일 점심 뭐 먹지?', '내일 공부 해야겠다.', '점심 먹고 공부 해야지!']\n",
        "count_vec = CountVectorizer(analyzer='word', ngram_range=(1,1), stop_words=['나는'])  # ngram_range 단어장 생성에 사용할 토큰 크기를 결정\n",
        "count_vec.fit(textData)\n",
        "print(count_vec.get_feature_names_out())\n",
        "print(count_vec.vocabulary_)  # {'나는': 2, '고프다': 0, '아니': 7, '배가': 6, '내일': 3, '점심': 8, '먹지': 5, '공부': 1, '해야겠다': 9, '먹고': 4, '해야지': 10}\n",
        "print([textData[0]])\n",
        "sentence = [textData[0]]\n",
        "print(count_vec.transform(sentence))  # 벡터화\n",
        "print(count_vec.transform(sentence).toarray())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TF~IDF : Term Frequency(1개의 문서 내 특정 단어 등장빈도) - Inverse Document Frequency\n",
        "# DF : 특정 단어가 나타나는 문장 수\n",
        "# 정보 검색과 텍스트 마이닝에서 이용하는 가중치로, 여러 문서로 이루어진 문서군이 있을 때 어떤 단어가 특정 문서 내에서 얼마나 중요한 것인지를 나타내는 통계적 수치\n",
        "# 단순히 빈도수로 그 단어의 가치를 정하는 것이 아니라, 여러 문장에 많이 등장하는 단어는 패널티를 주어 단어 빈도의 스케일을 맞추는 기법\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "textData = ['나는 배 고프다 아니 배가 고프다.', '내일 점심 뭐 먹지?', '내일 공부 해야겠다.', '점심 먹고 공부 해야지!']\n",
        "tfidf_vec = TfidfVectorizer(analyzer='word', ngram_range=(1,1), stop_words=['나는'])  # 모델 생성\n",
        "tfidf_vec.fit(textData)\n",
        "print(tfidf_vec.get_feature_names_out())\n",
        "print(tfidf_vec.vocabulary_)\n",
        "print(tfidf_vec.transform(textData).toarray())\n",
        "print()\n",
        "sentence = [textData[3]]\n",
        "print(sentence)\n",
        "print(tfidf_vec.transform(sentence))  # 벡터화\n",
        "print(tfidf_vec.transform(sentence).toarray())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2d-fJuFEWdAP",
        "outputId": "7fa89980-209c-45e9-98b0-6dc25786796a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['고프다' '공부' '내일' '먹고' '먹지' '배가' '아니' '점심' '해야겠다' '해야지']\n",
            "{'고프다': 0, '아니': 6, '배가': 5, '내일': 2, '점심': 7, '먹지': 4, '공부': 1, '해야겠다': 8, '먹고': 3, '해야지': 9}\n",
            "[[0.81649658 0.         0.         0.         0.         0.40824829\n",
            "  0.40824829 0.         0.         0.        ]\n",
            " [0.         0.         0.52640543 0.         0.66767854 0.\n",
            "  0.         0.52640543 0.         0.        ]\n",
            " [0.         0.52640543 0.52640543 0.         0.         0.\n",
            "  0.         0.         0.66767854 0.        ]\n",
            " [0.         0.43779123 0.         0.55528266 0.         0.\n",
            "  0.         0.43779123 0.         0.55528266]]\n",
            "\n",
            "['점심 먹고 공부 해야지!']\n",
            "  (0, 9)\t0.5552826649411127\n",
            "  (0, 7)\t0.43779123108611473\n",
            "  (0, 3)\t0.5552826649411127\n",
            "  (0, 1)\t0.43779123108611473\n",
            "[[0.         0.43779123 0.         0.55528266 0.         0.\n",
            "  0.         0.43779123 0.         0.55528266]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TfidfVectorizer를 사용해 텍스트(형태소 분석기 Okt를 적용)를 벡터로 변환 후 유사도 계산\n",
        "# ! pip install konlpy\n",
        "from konlpy.tag import Okt\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "7zhYCiREdFt6"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "okt = Okt()\n",
        "\n",
        "def tokenizeFunc(ss):  # 형태소 분석용 함수\n",
        "  ss = okt.normalize(ss)  # Okt는 정규화를 일부 지원함. 예)사랑햌 => 사랑해로 수정\n",
        "  ss = okt.morphs(ss)  # 형태소 단위로 분리. 반환형은 리스트\n",
        "  return ss\n",
        "\n",
        "texts = ['길동이는 파이썬을 좋아합니다', '길동이는 웹을 잘합니다', '길동이는 운동을 매우 잘합니다']\n",
        "new_texts = ['길동이는 파이썬을 좋아하고 운동을 잘합니다.']\n",
        "\n",
        "tfidf = TfidfVectorizer(tokenizer=tokenizeFunc, token_pattern=None).fit(texts)\n",
        "print(tfidf.vocabulary_)\n",
        "tfidf_matrix = tfidf.fit_transform(texts)  # 벡터형태로 변환\n",
        "print(tfidf_matrix)\n",
        "print(tfidf_matrix.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0MiHcD4wd6rr",
        "outputId": "f082e367-8fa6-4396-eee4-7bdda1f72727"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'길동': 0, '이': 6, '는': 1, '파이썬': 9, '을': 5, '좋아합니다': 8, '웹': 4, '잘': 7, '합니다': 10, '운동': 3, '매우': 2}\n",
            "  (0, 8)\t0.5427006131762078\n",
            "  (0, 5)\t0.32052772458725637\n",
            "  (0, 9)\t0.5427006131762078\n",
            "  (0, 1)\t0.32052772458725637\n",
            "  (0, 6)\t0.32052772458725637\n",
            "  (0, 0)\t0.32052772458725637\n",
            "  (1, 10)\t0.40352535506797127\n",
            "  (1, 7)\t0.40352535506797127\n",
            "  (1, 4)\t0.5305873490316616\n",
            "  (1, 5)\t0.31337343564910264\n",
            "  (1, 1)\t0.31337343564910264\n",
            "  (1, 6)\t0.31337343564910264\n",
            "  (1, 0)\t0.31337343564910264\n",
            "  (2, 2)\t0.4686986463592043\n",
            "  (2, 3)\t0.4686986463592043\n",
            "  (2, 10)\t0.356457401476207\n",
            "  (2, 7)\t0.356457401476207\n",
            "  (2, 5)\t0.27682097087637686\n",
            "  (2, 1)\t0.27682097087637686\n",
            "  (2, 6)\t0.27682097087637686\n",
            "  (2, 0)\t0.27682097087637686\n",
            "[[0.32052772 0.32052772 0.         0.         0.         0.32052772\n",
            "  0.32052772 0.         0.54270061 0.54270061 0.        ]\n",
            " [0.31337344 0.31337344 0.         0.         0.53058735 0.31337344\n",
            "  0.31337344 0.40352536 0.         0.         0.40352536]\n",
            " [0.27682097 0.27682097 0.46869865 0.46869865 0.         0.27682097\n",
            "  0.27682097 0.3564574  0.         0.         0.3564574 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for ntext in new_texts:\n",
        "  tftrans = tfidf.transform([ntext])  # 새로운 문장을 벡터로 변환   '길동이는 파이썬을 좋아하고 운동을 잘합니다.'\n",
        "  print('tftrans : \\n', tftrans)\n",
        "  # 새로운 문장과 기존 문장들 사이의 코사인 유사도 계산(데이터 크기 차이에 관계없이 계산)\n",
        "  cosine_simil = cosine_similarity(tftrans, tfidf_matrix)\n",
        "  print('cosine_simil : ', cosine_simil)  # [[0.6294     0.65051252 0.77272178]]\n",
        "\n",
        "# 출력\n",
        "print(f'새로운 문장 : {ntext}')\n",
        "print('----------')\n",
        "print(f'기존 문장 : ')\n",
        "for idx in range(3):\n",
        "  # print(cosine_simil.argsort()[0])  # [0]은 2차원 배열의 0행  [0 1 2]\n",
        "  # print((idx + 1) * -1)\n",
        "  print(cosine_simil[0][(idx + 1) * -1])\n",
        "  most_simil_idx = cosine_simil.argsort()[0][(idx + 1) + -1]\n",
        "  print(most_simil_idx)\n",
        "  most_simil_sentence = texts[most_simil_idx]\n",
        "  simil_score = cosine_simil[0][most_simil_idx]\n",
        "  print(f'{most_simil_sentence}(유사도:{simil_score:.3f})')\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8rmXhKfgkIY",
        "outputId": "638893de-3ef5-4935-f450-9f923a13c4bc"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tftrans : \n",
            "   (0, 10)\t0.3214212466114349\n",
            "  (0, 9)\t0.4226303131144919\n",
            "  (0, 7)\t0.3214212466114349\n",
            "  (0, 6)\t0.2496122711403758\n",
            "  (0, 5)\t0.4992245422807516\n",
            "  (0, 3)\t0.4226303131144919\n",
            "  (0, 1)\t0.2496122711403758\n",
            "  (0, 0)\t0.2496122711403758\n",
            "cosine_simil :  [[0.6294     0.65051252 0.77272178]]\n",
            "새로운 문장 : 길동이는 파이썬을 좋아하고 운동을 잘합니다.\n",
            "----------\n",
            "기존 문장 : \n",
            "0.7727217765585208\n",
            "0\n",
            "길동이는 파이썬을 좋아합니다(유사도:0.629)\n",
            "0.6505125202677131\n",
            "1\n",
            "길동이는 웹을 잘합니다(유사도:0.651)\n",
            "0.6293999965624972\n",
            "2\n",
            "길동이는 운동을 매우 잘합니다(유사도:0.773)\n"
          ]
        }
      ]
    }
  ]
}