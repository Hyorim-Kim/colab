{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO6b6shIK7J6V7tFAHSU6qt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hyorim-Kim/numpi/blob/main/tfc21word2vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7AVc4KkRycF",
        "outputId": "2c368095-a7ef-4383-a2f7-d8c4cc440003"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['살이 찔까 봐 카페에서 다양한 커피 메뉴를 뒤로하고 아메리카노를 선택하는 사람이 많다. 실제로 아메리카노는 열량은 한 잔에 약 10kcal 수준으로 아이스 카페모카(약 250kcal)와 비교하면 상대적으로 열량이 낮은 편이다. 그러나 아메리카노라고 해도 살에서 자유로운 건 아니다. 과하게 섭취했다간 오히려 살이 찔 수 있다.', '◇스트레스 호르몬 분비시켜 배고픔 유발', '열량이 낮다고 방심해서 많이 마셨다간 호르몬에 영향을 끼쳐 살이 찔 수 있다. 기본적으로 커피 속 카페인 성분은 몸속에 들어오면 심장박동수와 호흡률을 증가시키고, 불안하고 긴장된 느낌을 유발한다. 이런 상태는 일명 스트레스 호르몬이라 불리는 코르티솔 수치를 높인다. 코르티솔 분비가 활발해지면 렙틴이라는 식욕 억제 호르몬의 작용이 방해를 받는다. 결국, 식욕을 자극해 배가 고프지 않은데도 자꾸 음식을 찾게 된다. 가짜 배고픔을 유발할 수 있다.', '', '◇과하면 오히려 체내 독소 배출 막아 살찌는 체질로', '또 코르티솔은 지방 분해를 막아 지방이 체내에 쌓이게 한다. 특히 복부에는 호르몬 수용체가 많기 때문에 복부 지방이 생기기 쉽다. 장기간 많은 양의 카페인을 섭취하면 활성화됐던 교감신경을 억제하기 위해 부교감신경이 활성화된다. 카페인으로 빨라졌던 심장 박동이 느려지고, 이뇨작용이 원활하게 되지 않아 체내 독소 배출이 잘되지 않는다. 살찌는 체질로 이어질 수 있다.', '', '◇콜레스테롤 수치 1%가량 높이기도', '콜레스테롤에도 주의해야 한다. 아메리카노는 에스프레소를 물로 희석해 만든다. 그런데 에스프레소에는 카페스테롤이라는 화학물질이 있다. 카페스테롤은 간 효소 수치, 혈중 콜레스테롤 수치를 높인다. 실제 네덜란드 연구팀에 따르면 아메리카노 한 잔에 카페스테롤이 4mg 정도 들어 있으며, 이는 콜레스테롤 수치를 1%가량 높일 수 있다.', '열량이 낮은 아메리카노라도 적당량 마셔야 한다. 식품의약품안전처가 제시하는 성인 기준 1일 최대 카페인 섭취 권고량은 400mg이다.', 'Copyright© 헬스조선. 무단전재 및 재배포 금지.', '', '']\n"
          ]
        }
      ],
      "source": [
        "# daum 페이지의 뉴스 기사를 읽어 형태소 분석 후 word2vec을 이용해 단어 간 유사도 확인\n",
        "# !pip install konlpy\n",
        "from konlpy.tag import Okt\n",
        "import pandas as pd\n",
        "\n",
        "okt = Okt()\n",
        "\n",
        "with open('news.txt', mode='r') as obj:\n",
        "  lines = obj.read().split('\\n')\n",
        "\n",
        "print(lines)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 명사만 추출해 단어 빈도 수를 확인\n",
        "wordDic = {}\n",
        "\n",
        "for line in lines:\n",
        "  datas = okt.pos(line)  # 품사 태깅\n",
        "  # print(datas)\n",
        "  for word in datas:\n",
        "    if word[1] == 'Noun':\n",
        "      # print(word[0])\n",
        "      if len(word[0]) >= 2:\n",
        "        if not(word[0] in wordDic):\n",
        "          wordDic[word[0]] = 1\n",
        "        wordDic[word[0]] += 1\n",
        "\n",
        "print(wordDic)\n",
        "\n",
        "keys = sorted(wordDic.items(), key=lambda x:x[1], reverse=True)\n",
        "print(keys)\n",
        "\n",
        "# keys 자료를 DataFrame에 담기\n",
        "wordList = []\n",
        "countList = []\n",
        "for word, count in keys[:20]:\n",
        "  wordList.append(word)\n",
        "  countList.append(count)\n",
        "\n",
        "df = pd.DataFrame()\n",
        "df['word'] = wordList\n",
        "df['count'] = countList\n",
        "print(df.head(3))\n",
        "\n",
        "# pandas의 기능으로 기술통계 작업 처리 .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPjAQ54AUpD6",
        "outputId": "4f9a45da-2dd9-405d-e89d-d6572506f8c6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'살이': 4, '카페': 5, '커피': 3, '메뉴': 2, '뒤로': 2, '아메리카노': 7, '선택': 2, '사람': 2, '실제': 3, '열량': 5, '수준': 2, '아이스': 2, '카페모카': 2, '비교': 2, '상대': 2, '편이': 2, '해도': 2, '섭취': 4, '오히려': 3, '스트레스': 3, '호르몬': 6, '분비': 3, '유발': 4, '영향': 2, '기본': 2, '카페인': 5, '성분': 2, '몸속': 2, '심장': 3, '박동수': 2, '호흡': 2, '증가': 2, '긴장': 2, '느낌': 2, '상태': 2, '일명': 2, '코르티솔': 4, '수치': 6, '렙틴': 2, '식욕': 3, '억제': 3, '작용': 2, '방해': 2, '자극': 2, '자꾸': 2, '음식': 2, '가짜': 2, '체내': 4, '독소': 3, '배출': 3, '체질': 3, '지방': 4, '분해': 2, '복부': 3, '수용체': 2, '때문': 2, '장기간': 2, '활성화': 3, '교감신경': 2, '위해': 2, '부교감신경': 2, '박동': 2, '용이': 2, '잘되지': 2, '콜레스테롤': 5, '가량': 3, '주의': 2, '에스프레소': 3, '스테롤': 4, '화학물질': 2, '효소': 2, '혈중': 2, '네덜란드': 2, '정도': 2, '적당': 2, '식품의약품안전처': 2, '제시': 2, '성인': 2, '기준': 2, '최대': 2, '고량': 2, '헬스': 2, '조선': 2, '무단': 2, '배포': 2, '금지': 2}\n",
            "[('아메리카노', 7), ('호르몬', 6), ('수치', 6), ('카페', 5), ('열량', 5), ('카페인', 5), ('콜레스테롤', 5), ('살이', 4), ('섭취', 4), ('유발', 4), ('코르티솔', 4), ('체내', 4), ('지방', 4), ('스테롤', 4), ('커피', 3), ('실제', 3), ('오히려', 3), ('스트레스', 3), ('분비', 3), ('심장', 3), ('식욕', 3), ('억제', 3), ('독소', 3), ('배출', 3), ('체질', 3), ('복부', 3), ('활성화', 3), ('가량', 3), ('에스프레소', 3), ('메뉴', 2), ('뒤로', 2), ('선택', 2), ('사람', 2), ('수준', 2), ('아이스', 2), ('카페모카', 2), ('비교', 2), ('상대', 2), ('편이', 2), ('해도', 2), ('영향', 2), ('기본', 2), ('성분', 2), ('몸속', 2), ('박동수', 2), ('호흡', 2), ('증가', 2), ('긴장', 2), ('느낌', 2), ('상태', 2), ('일명', 2), ('렙틴', 2), ('작용', 2), ('방해', 2), ('자극', 2), ('자꾸', 2), ('음식', 2), ('가짜', 2), ('분해', 2), ('수용체', 2), ('때문', 2), ('장기간', 2), ('교감신경', 2), ('위해', 2), ('부교감신경', 2), ('박동', 2), ('용이', 2), ('잘되지', 2), ('주의', 2), ('화학물질', 2), ('효소', 2), ('혈중', 2), ('네덜란드', 2), ('정도', 2), ('적당', 2), ('식품의약품안전처', 2), ('제시', 2), ('성인', 2), ('기준', 2), ('최대', 2), ('고량', 2), ('헬스', 2), ('조선', 2), ('무단', 2), ('배포', 2), ('금지', 2)]\n",
            "    word  count\n",
            "0  아메리카노      7\n",
            "1    호르몬      6\n",
            "2     수치      6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 단어 간 유사도 구하기\n",
        "results = []  # 한글만 기억\n",
        "\n",
        "with open('news.txt', mode='r') as obj:\n",
        "  lines = obj.read().split('\\n')\n",
        "\n",
        "for line in lines:\n",
        "  datas = okt.pos(line, stem=True)  # 원형 어근으로 출력   한가한 : 한가하다\n",
        "  # print(datas)\n",
        "  imsi = []\n",
        "  for word in datas:\n",
        "    if not word[1] in ['Number', 'Josa', 'Punctuation', 'Alpha', 'Modifier', 'Foreign', 'Suffix']:\n",
        "      if len(word[0]) >= 2:\n",
        "        imsi.append(word[0])\n",
        "  imsi2 = ('  '.join(imsi)).strip()\n",
        "  results.append(imsi2)\n"
      ],
      "metadata": {
        "id": "7Z3rikZWXyAr"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(results)\n",
        "\n",
        "fileName = 'daumnews.txt'\n",
        "with open(fileName, mode='w') as obj:\n",
        "  obj.write('\\n'.join(results))\n",
        "\n",
        "from gensim.models import word2vec\n",
        "\n",
        "lineObj = word2vec.LineSentence(fileName)\n",
        "\n",
        "model = word2vec.Word2Vec(sentences=lineObj, vector_size=100, window=10, min_count=1, sg=1)\n",
        "# sg=0: CBOW(주변단어로 중심단어를 예측), sg=1: Skip-Gram(중심단어로 주변단어를 예측)\n",
        "print(model)\n",
        "\n",
        "# model.init_sims(replace=True)  # 필요없는 메모리 해제\n",
        "\n",
        "# positive : 단어 사전에 해당 단어가 있을 확률. 가까운 단어 찾음\n",
        "# negative : 단어 사전에 해당 단어가 없을 확률. 먼 단어 찾음\n",
        "print(model.wv.most_similar(positive=['열량']))  # 긍정적 기여 목록\n",
        "print(model.wv.most_similar(negative=['열량']))  # 부정적 기여 목록\n",
        "print(model.wv.most_similar(positive=['열량', '효소'], topn=5))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCeUK63MaU5e",
        "outputId": "a965e1a2-98b3-4ffa-eb28-5addd4cc156b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['살이  찌다  보다  카페  다양하다  커피  메뉴  뒤로  아메리카노  선택  하다  사람  많다  실제  아메리카노  열량  하다  수준  아이스  카페모카  오다  비교  하다  상대  열량  낮다  편이  그러나  아메리카노  해도  자유롭다  아니다  하다  섭취  하다  오히려  살이  찌다  있다', '스트레스  호르몬  분비  시키다  배고프다  유발', '열량  낮다  방심하다  많이  마시다  호르몬  영향  끼치다  살이  찌다  있다  기본  커피  카페인  성분  몸속  들어오다  심장  박동수  호흡  증가  시키다  불안하다  긴장  되다  느낌  유발  하다  이렇다  상태  일명  스트레스  호르몬  불리다  코르티솔  수치  높이다  코르티솔  분비  활발해지다  렙틴  식욕  억제  호르몬  작용  방해  받다  결국  식욕  자극  하다  고프다  않다  자꾸  음식  찾다  되다  가짜  배고프다  유발  하다  있다', '', '하다  오히려  체내  독소  배출  막다  살찌다  체질', '코르티솔  지방  분해  막다  지방  체내  쌓이다  하다  특히  복부  호르몬  수용체  많다  때문  복부  지방  생기다  쉬다  장기간  많다  카페인  섭취  하다  활성화  돼다  교감신경  억제  하다  위해  부교감신경  활성화  되다  카페인  빨르다  심장  박동  느리다  용이  원활하다  되다  않다  체내  독소  배출  잘되지  않다  살찌다  체질  이어지다  있다', '', '콜레스테롤  수치  가량  높다', '콜레스테롤  주의  하다  하다  아메리카노  에스프레소  희다  만들다  그런데  에스프레소  카페  스테롤  화학물질  있다  카페  스테롤  효소  수치  혈중  콜레스테롤  수치  높이다  실제  네덜란드  따르다  아메리카노  하다  카페  스테롤  정도  들다  있다  이다  콜레스테롤  수치  가량  높이다  있다', '열량  낮다  아메리카노  적당  마시다  하다  식품의약품안전처  제시  하다  성인  기준  최대  카페인  섭취  고량', '헬스  조선  무단  배포  금지', '', '']\n",
            "Word2Vec<vocab=133, vector_size=100, alpha=0.025>\n",
            "[('사람', 0.27026569843292236), ('제시', 0.2677687108516693), ('하다', 0.24978092312812805), ('메뉴', 0.22785940766334534), ('영향', 0.22721056640148163), ('느낌', 0.18342183530330658), ('때문', 0.1820192039012909), ('음식', 0.17981278896331787), ('그런데', 0.1637897789478302), ('몸속', 0.14604663848876953)]\n",
            "[('실제', 0.21578215062618256), ('수치', 0.16166488826274872), ('효소', 0.15053333342075348), ('호르몬', 0.14516489207744598), ('기본', 0.14364901185035706), ('위해', 0.13888712227344513), ('높이다', 0.13755109906196594), ('호흡', 0.1357898861169815), ('박동수', 0.13341444730758667), ('증가', 0.13134729862213135)]\n",
            "[('때문', 0.26676294207572937), ('식욕', 0.2371203899383545), ('몸속', 0.2311689555644989), ('사람', 0.21969929337501526), ('제시', 0.21595783531665802)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 유사도를 이용한 추천 시스템 구현하기\n",
        "import pandas as pd\n",
        "\n",
        "# DtypeWarning : 열 (2,36,37)에 혼합 유형이 있다. 가져 오기의 경우에 dtype 옵션을 지정하거나 low_memory = False를 설정.\n",
        "data = pd.read_csv(\"https://raw.githubusercontent.com/pykwon/python/master/testdata_utf8/movies_metadata.csv\", encoding = 'ISO-8859-1', low_memory=False)\n",
        "print(data.head(2))       # [2 rows x 45 columns]\n",
        "data=data.head(20000)\n",
        "print(data['overview'].isnull().sum())  # 135\n",
        "data['overview'] = data['overview'].fillna('')    # overview에서 Null 값을 가진 경우에는 값 제거\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x0eSLw-hj8PJ",
        "outputId": "6289add6-cb86-4db5-edf0-269bf5df7e03"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   adult                              belongs_to_collection    budget  \\\n",
            "0  FALSE  {'id': 10194, 'name': 'Toy Story Collection', ...  30000000   \n",
            "1  FALSE                                                NaN  65000000   \n",
            "\n",
            "                                              genres  \\\n",
            "0  [{'id': 16, 'name': 'Animation'}, {'id': 35, '...   \n",
            "1  [{'id': 12, 'name': 'Adventure'}, {'id': 14, '...   \n",
            "\n",
            "                               homepage    id    imdb_id original_language  \\\n",
            "0  http://toystory.disney.com/toy-story   862  tt0114709                en   \n",
            "1                                   NaN  8844  tt0113497                en   \n",
            "\n",
            "  original_title                                           overview  ...  \\\n",
            "0      Toy Story  Led by Woody, Andy's toys live happily in his ...  ...   \n",
            "1        Jumanji  When siblings Judy and Peter discover an encha...  ...   \n",
            "\n",
            "  Unnamed: 35 Unnamed: 36 Unnamed: 37 Unnamed: 38 Unnamed: 39 Unnamed: 40  \\\n",
            "0         NaN         NaN         NaN         NaN         NaN         NaN   \n",
            "1         NaN         NaN         NaN         NaN         NaN         NaN   \n",
            "\n",
            "  Unnamed: 41 Unnamed: 42 Unnamed: 43 Unnamed: 44  \n",
            "0         NaN         NaN         NaN         NaN  \n",
            "1         NaN         NaN         NaN         NaN  \n",
            "\n",
            "[2 rows x 45 columns]\n",
            "135\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 이제 tf-idf를 수행\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "tfidf_matrix = tfidf.fit_transform(data['overview'])\n",
        "# overview에 대해서 tf-idf 수행\n",
        "print(tfidf_matrix.shape)  # (20000, 47181)\n",
        "\n",
        "# overview 열에 대해서 tf-idf를 수행했다. 20,000개의 영화를 표현하기 위해 총 47,487개의 단어가 사용되었음을 보여주고 있다. 이제 코사인 유사도를 사용하면 바로 문서의 유사도를 구할 수 있다.\n",
        "\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)  # 코사인 유사도\n",
        "indices = pd.Series(data.index, index=data['title']).drop_duplicates()\n",
        "print(indices.head())\n",
        "\n",
        "# 이 테이블의 용도는 영화의 타이틀을 입력하면 인덱스를 리턴하기 위함.\n",
        "idx = indices['Father of the Bride Part II']\n",
        "print(idx)   # 4\n",
        "\n",
        "# 이제 선택한 영화에 대해서 코사인 유사도를 이용하여, 가장 overview가 유사한 10개의 영화를 찾아내는 함수를 만든다.\n",
        "def get_recommendations(title, cosine_sim=cosine_sim):\n",
        "    # 선택한 영화의 타이틀로부터 해당되는 인덱스를 받아옵니다. 이제 선택한 영화를 가지고 연산할 수 있다.\n",
        "    idx = indices[title]\n",
        "    sim_scores = list(enumerate(cosine_sim[idx]))  # 모든 영화에 대해서 해당 영화와의 유사도를 구한다.\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)  # 유사도에 따라 영화들을 정렬\n",
        "    sim_scores = sim_scores[1:11]                   # 가장 유사한 10개의 영화를 받아온다.\n",
        "    movie_indices = [i[0] for i in sim_scores]     # 가장 유사한 10개의 영화의 인덱스를 받아온다.\n",
        "    return data['title'].iloc[movie_indices]           # 가장 유사한 10개의 영화의 제목을 리턴\n",
        "\n",
        "# 영화 다크 나이트 라이즈와 overview가 유사한 영화들을 찾아보겠다.\n",
        "print(get_recommendations('The Dark Knight Rises'))333\n",
        "\n",
        "# 가장 유사한 영화가 출력되는데, 영화 다크 나이트가 첫번째고, 그 외에도 전부 배트맨 영화를 찾아낸 것을 확인할 수 있다.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0ZEEc5skQhR",
        "outputId": "d3e55a4a-ca17-42ab-b8fa-94e84a0e4af5"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20000, 47181)\n",
            "title\n",
            "Toy Story                      0\n",
            "Jumanji                        1\n",
            "Grumpier Old Men               2\n",
            "Waiting to Exhale              3\n",
            "Father of the Bride Part II    4\n",
            "dtype: int64\n",
            "4\n",
            "12479                            The Dark Knight\n",
            "150                               Batman Forever\n",
            "1328                              Batman Returns\n",
            "15508                 Batman: Under the Red Hood\n",
            "585                                       Batman\n",
            "9227          Batman Beyond: Return of the Joker\n",
            "18032                           Batman: Year One\n",
            "19789    Batman: The Dark Knight Returns, Part 1\n",
            "3094                Batman: Mask of the Phantasm\n",
            "10119                              Batman Begins\n",
            "Name: title, dtype: object\n"
          ]
        }
      ]
    }
  ]
}